{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec, KeyedVectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_DIM = 300\n",
    "count_analyzer = CountVectorizer().build_analyzer()\n",
    "tfidf_analyzer = TfidfVectorizer().build_analyzer()\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "def preprocessor(review):\n",
    "    return BeautifulSoup(review, 'html5lib').get_text()\n",
    "\n",
    "def stem_analyzer(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "def get_vectors(reviews, vocabulary):\n",
    "    X = []\n",
    "    for review in reviews:\n",
    "        num = 0\n",
    "        review_vector = np.zeros(MODEL_DIM)\n",
    "\n",
    "        for i in range(len(review)):\n",
    "            weight = review[i]\n",
    "            if weight == 0:\n",
    "                continue\n",
    "\n",
    "            word = vocabulary[i]\n",
    "            if not model.vocab.has_key(word):\n",
    "                continue\n",
    "            \n",
    "            vector = model[word]\n",
    "            review_vector += vector * weight\n",
    "            num = num + 1\n",
    "\n",
    "        if num > 0:\n",
    "            review_vector = review_vector / num\n",
    "\n",
    "        X.append(review_vector)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "train = pd.read_csv(\"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_v = CountVectorizer(analyzer=count_analyzer, preprocessor=preprocessor, stop_words='english', max_features=5000)\n",
    "tfidf_v = TfidfVectorizer(analyzer=tfidf_analyzer, preprocessor=preprocessor, stop_words='english', max_features=5000)\n",
    "\n",
    "train_reviews = [r for r in train.review]\n",
    "test_reviews = [r for r in test.review]\n",
    "\n",
    "count_v.fit(train_reviews)\n",
    "tfidf_v.fit(train_reviews)\n",
    "\n",
    "train_reviews_count_trans = count_v.transform(train_reviews).toarray()\n",
    "train_reviews_tfidf_trans = tfidf_v.transform(train_reviews).toarray()\n",
    "\n",
    "test_reviews_count_trans = count_v.transform(test_reviews).toarray()\n",
    "test_reviews_tfidf_trans = tfidf_v.transform(test_reviews).toarray()\n",
    "\n",
    "count_vocabulary = count_v.get_feature_names()\n",
    "tfidf_vocabulary = tfidf_v.get_feature_names()\n",
    "\n",
    "X_all_count = get_vectors(train_reviews_count_trans, count_vocabulary)\n",
    "X_all_tfidf = get_vectors(train_reviews_tfidf_trans, tfidf_vocabulary)\n",
    "\n",
    "X_test_count = get_vectors(test_reviews_count_trans, count_vocabulary)\n",
    "X_test_tfidf = get_vectors(test_reviews_tfidf_trans, tfidf_vocabulary)\n",
    "\n",
    "y_all = train.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez_compressed(\"word2vec_count_vectorized_data.npz\", X_all=X_all_count, X_test=X_test_count, y_all = y_all)\n",
    "#np.savez_compressed(\"word2vec_tfidf_vectorized_data.npz\", X_all=X_all_tfidf, X_test=X_test_tfidf, y_all = y_all)\n",
    "\n",
    "data = np.load('word2vec_count_vectorized_data.npz')\n",
    "X_all, X_test, y_all = data['X_all'], data['X_test'], data['y_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "# 比较高维的时候，LogisticRegression这样简单的算法竟然效果是最好，RandomForestClassifier表现比较差\n",
    "#from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "X_all_std = StandardScaler().fit_transform(X_all)\n",
    "```\n",
    "不用Bag-of-centroid的时候，std有效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5000, max_iter=10, n_jobs=8)\n",
    "kmeans.fit(X_all)\n",
    "X_all_km_centroids = [kmeans.cluster_centers_[idx] for idx in kmeans.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minibatchkmeans = MiniBatchKMeans(n_clusters=5000, max_iter=10)\n",
    "minibatchkmeans.fit(X_all)\n",
    "X_all_mbkm_centroids = [minibatchkmeans.cluster_centers_[idx] for idx in minibatchkmeans.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(LogisticRegression(), X_all, y_all) #works best\n",
    "cross_val_score(RidgeClassifier(), X_all, y_all)\n",
    "cross_val_score(SVC(), X_all, y_all)\n",
    "\n",
    "cross_val_score(LogisticRegression(), X_all_km_centroids, y_all)\n",
    "cross_val_score(LogisticRegression(), X_all_mbkm_centroids, y_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
